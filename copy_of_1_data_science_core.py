# -*- coding: utf-8 -*-
"""Copy of 1_data_science_core.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1koWJf1jTUTf09scb_QihiCq-cpnetM1O

# Phase 1: Data Science Core

This notebook covers the complete data science workflow for training and evaluating predictive maintenance models. We will build two separate models:
1.  **Engine Fault Detection Model**
2.  **Naval Vessel Condition Model**
"""



"""## Model 1: Engine Fault Detection
---
This section focuses on the `engine_fault_detection_dataset.csv` to predict engine conditions.

### 1.1. Environment Setup & Library Imports
First, let's import all the necessary libraries for this analysis.
"""

# Core data science libraries
import pandas as pd
import numpy as np

# Visualization libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning libraries
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import xgboost as xgb

# Model explainability
import shap

# Model persistence
import joblib

# Set some display options for better readability
pd.set_option('display.max_columns', None)
sns.set_style('whitegrid')

print("Libraries imported successfully.")

"""### 1.2. Exploratory Data Analysis (EDA)
Load the dataset and perform an initial analysis to understand its structure, check for missing values, and visualize the distributions.
"""

# Load the dataset
try:
    df_engine = pd.read_csv('data/engine_fault_detection_dataset.csv')
    print("Engine fault detection dataset loaded successfully.")
    display(df_engine.head())
except FileNotFoundError:
    print("Error: The file 'engine_fault_detection_dataset.csv' was not found in the 'data' directory.")
    print("Please ensure the dataset is in the correct location.")

# Get a concise summary of the dataframe
print("DataFrame Info:")
df_engine.info()

# Check for missing values
print("\nMissing Values Check:")
print(df_engine.isnull().sum())

!zip -r project.zip /content

"""#### Analyze Target Variable
Let's visualize the distribution of the `Engine_Condition` target variable to confirm the class imbalance.
"""

# Let's investigate the 'Engine_Condition' column to resolve the error.
# First, inspect the unique values to see what we're dealing with.
print("Original unique values in 'Engine_Condition':", df_engine['Engine_Condition'].unique())

# The error suggests the values are strings. Let's safely convert them to numbers.
# pd.to_numeric is safer than .astype(int) as it can handle potential errors.
df_engine['Engine_Condition'] = pd.to_numeric(df_engine['Engine_Condition'], errors='coerce')

# Drop rows where conversion might have failed (resulting in NaN)
df_engine.dropna(subset=['Engine_Condition'], inplace=True)

# Now, convert to integer since we've handled errors
df_engine['Engine_Condition'] = df_engine['Engine_Condition'].astype(int)

print("Cleaned unique values in 'Engine_Condition':", df_engine['Engine_Condition'].unique())


# Now, let's recreate the plot with the corrected data type
# We will also update the call to address the FutureWarning
plt.figure(figsize=(8, 6))
sns.countplot(
    x='Engine_Condition',
    data=df_engine,
    palette={0: '#10B981', 1: '#F59E0B', 2: '#EF4444'},
    hue='Engine_Condition',  # Assign hue to get rid of the warning
    legend=False             # Hide the legend as it's redundant here
)
plt.title('Distribution of Engine Condition')
plt.xlabel('Engine Condition (0: Normal, 1: Minor, 2: Critical)')
plt.ylabel('Count')

# Calculate and display percentages
total = len(df_engine)
ax = plt.gca()
for p in ax.patches:
    height = p.get_height()
    if height > 0: # Avoid adding text to empty bars
        ax.text(p.get_x() + p.get_width()/2.,
                height + 5,
                '{:1.1f}%'.format(100 * height/total),
                ha="center")

plt.show()

"""#### Analyze Feature Distributions
Now, let's visualize the distributions of the 11 sensor features to understand their characteristics.
"""

# Separate features (X) from the target (y)
features = df_engine.drop('Engine_Condition', axis=1)

# Plot histograms for all features
plt.figure(figsize=(16, 12))
for i, col in enumerate(features.columns):
    plt.subplot(4, 3, i + 1)
    sns.histplot(df_engine[col], kde=True)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

"""#### Analyze Feature Correlations
A correlation heatmap is a great way to see how the features relate to each other. This can help identify redundant features or interesting relationships.
"""

# Calculate the correlation matrix
corr_matrix = df_engine.corr()

# Plot the heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix of All Features')
plt.show()

"""### 1.3. Data Preprocessing
Here, we'll split the data into features (X) and target (y), and then divide it into training and testing sets. This is a critical step before training the model.
"""

# Define features (X) and target (y)
X = df_engine.drop('Engine_Condition', axis=1)
y = df_engine['Engine_Condition']

# Split the data into training and testing sets (80/20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("Data split into training and testing sets.")
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""#### Handle Class Imbalance with SMOTE
As we saw in the EDA, the dataset is imbalanced. We will use the **Synthetic Minority Over-sampling TEchnique (SMOTE)** to address this.

**CRITICAL:** SMOTE should only be applied to the *training* data. Applying it to the test data would lead to data leakage and an overly optimistic evaluation of the model's performance.
"""

# Initialize SMOTE
smote = SMOTE(random_state=42)

# Apply SMOTE to the training data
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print("SMOTE applied to the training data.")
print("Original training set shape:", y_train.value_counts())
print("Resampled training set shape:", y_train_resampled.value_counts())

# Visualize the balanced training data
plt.figure(figsize=(8, 6))
sns.countplot(x=y_train_resampled, palette={0: '#10B981', 1: '#F59E0B', 2: '#EF4444'}, hue=y_train_resampled, legend=False)
plt.title('Distribution of Engine Condition in Resampled Training Data')
plt.xlabel('Engine Condition')
plt.ylabel('Count')
plt.show()

"""### 1.4. Model Training (XGBoost)
Now we will train the XGBoost classifier on the balanced training data.
"""

# Initialize the XGBoost Classifier
# The parameters are set according to the project plan for a multi-class classification problem.
xgb_model = xgb.XGBClassifier(
    objective='multi:softmax',
    num_class=3,
    use_label_encoder=False,  # Suppress a deprecation warning
    eval_metric='mlogloss',   # Evaluation metric for multi-class classification
    random_state=42
)

# Train the model on the resampled training data
print("Training the XGBoost model...")
xgb_model.fit(X_train_resampled, y_train_resampled)
print("Model training complete.")

"""### 1.5. Model Evaluation
With the model trained, we'll now evaluate its performance on the original, unseen test set. This gives us a realistic measure of how the model will perform on new data.
"""

# Make predictions on the test set
y_pred = xgb_model.predict(X_test)

# Generate and print the classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=['Normal (0)', 'Minor Fault (1)', 'Critical Fault (2)']))

# Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Normal', 'Minor Fault', 'Critical Fault'],
            yticklabels=['Normal', 'Minor Fault', 'Critical Fault'])
plt.title('Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

"""### 1.6. Model Explainability (SHAP)
Now that we have a trained model, let's use SHAP to understand how it makes predictions. This is the core of the "Explainable AI" part of the project.
"""

# Initialize the SHAP explainer
# For tree-based models like XGBoost, the TreeExplainer is the most efficient.
explainer = shap.TreeExplainer(xgb_model)

# Calculate SHAP values for the test set
# This can take a moment as it calculates the contribution of each feature to each prediction.
print("Calculating SHAP values for the test set...")
shap_values = explainer(X_test)
print("SHAP values calculated.")

# The output `shap_values` is a special object containing values, base values, and data.
# For a multi-class model, shap_values.values will be a list of arrays, one for each class.
# Let's check the shape for one class.
print("Shape of SHAP values for one class:", shap_values.values[0].shape)

"""#### Global Feature Importance
The SHAP summary plot provides a powerful visualization of global feature importance, showing not just *which* features are important, but also *how* they affect the model's output.
"""

# Generate the SHAP summary plot
# This plot shows the impact of each feature on the model's output.
# Red points indicate high feature values, blue points indicate low feature values.
print("SHAP Summary Plot for Critical Faults (Class 2)")
shap.summary_plot(shap_values[:,:,2], X_test, plot_type="dot")

print("\nSHAP Summary Plot for Minor Faults (Class 1)")
shap.summary_plot(shap_values[:,:,1], X_test, plot_type="dot")

print("\nSHAP Summary Plot for Normal Condition (Class 0)")
shap.summary_plot(shap_values[:,:,0], X_test, plot_type="dot")

"""### 1.7. Model Serialization
Finally, we save our trained model and the SHAP explainer to disk. These files will be loaded by our FastAPI backend to make live predictions. We'll save them in the `backend` directory.
"""

# Define the paths to save the model and explainer
model_path = 'models/marine_model.pkl'
explainer_path = 'models/shap_explainer.pkl'

# Save the model
joblib.dump(xgb_model, model_path)
print(f"Model saved to {model_path}")

# Save the SHAP explainer
joblib.dump(explainer, explainer_path)
print(f"SHAP explainer saved to {explainer_path}")

"""---
## Model 2: Naval Vessel Condition Prediction
---
This section focuses on the `Predictive_Maintenance_Naval_Vessel_Condition.csv` dataset. We will follow a similar workflow to build a second predictive model.

### 2.1. Load and Inspect the Naval Vessel Dataset
"""

# Load the second dataset
try:
    df_naval = pd.read_csv('data/Predictive_Maintenance_Naval_Vessel_Condition.csv')
    print("Naval vessel condition dataset loaded successfully.")
    display(df_naval.head())
except FileNotFoundError:
    print("Error: The file 'Predictive_Maintenance_Naval_Vessel_Condition.csv' was not found in the 'data' directory.")

# Get a concise summary of the dataframe
print("\nDataFrame Info:")
df_naval.info()

# Check for missing values
print("\nMissing Values Check:")
print(df_naval.isnull().sum())

"""### 2.2. Data Cleaning and EDA for Naval Vessel Data"""

# Step 1: Drop unnecessary columns
if 'Unnamed: 0' in df_naval.columns:
    df_naval = df_naval.drop('Unnamed: 0', axis=1)
    print("Dropped 'Unnamed: 0' column.")
if 'index' in df_naval.columns:
    df_naval = df_naval.drop('index', axis=1)
    print("Dropped 'index' column.")

# Step 2: Clean column names
# XGBoost doesn't allow special characters like '[', ']', or '<' in feature names.
# We will use regex to remove them, and also strip whitespace and replace other chars.
original_cols = df_naval.columns.tolist()
df_naval.columns = df_naval.columns.str.replace('[\[\]()]', '', regex=True).str.strip().str.replace(' ', '_').str.replace('.', '')
cleaned_cols = df_naval.columns.tolist()

print("Column names cleaned for XGBoost compatibility.")
# Display a mapping of old to new names for clarity
print("\nColumn Name Changes:")
for old, new in zip(original_cols, cleaned_cols):
    if old != new:
        print(f"'{old}' -> '{new}'")


# Step 3: Define target columns using the *cleaned* names
target_cols = ['GT_Compressor_decay_state_coefficient', 'GT_Turbine_decay_state_coefficient']
print("\nCleaned target columns:", target_cols)

# Step 4: Plot distributions of the target variables
print("\nPlotting target variable distributions...")
plt.figure(figsize=(14, 5))

# Plot for Compressor decay
plt.subplot(1, 2, 1)
sns.histplot(df_naval[target_cols[0]], kde=True, color='blue')
plt.title('Distribution of Compressor Decay State')

# Plot for Turbine decay
plt.subplot(1, 2, 2)
sns.histplot(df_naval[target_cols[1]], kde=True, color='green')
plt.title('Distribution of Turbine Decay State')

plt.tight_layout()
plt.show()

"""#### Analyze Feature Distributions and Correlations"""

# Define feature columns
feature_cols = [col for col in df_naval.columns if col not in target_cols]

# Plot histograms for all features
plt.figure(figsize=(20, 16))
for i, col in enumerate(feature_cols):
    plt.subplot(5, 4, i + 1)
    sns.histplot(df_naval[col], kde=True)
    plt.title(f'Distribution of {col}', fontsize=10)
    plt.xlabel('')
    plt.ylabel('')
plt.tight_layout()
plt.show()

# Plot the correlation heatmap
plt.figure(figsize=(18, 15))
sns.heatmap(df_naval.corr(), annot=False, cmap='coolwarm')
plt.title('Correlation Matrix of All Naval Variables')
plt.show()

"""### 2.3. Data Preprocessing for Regression Model
Now, we'll separate the features from the target variables and split the data into training and testing sets.
"""

# Define features (X) and targets (y)
X_naval = df_naval.drop(columns=target_cols)
y_naval = df_naval[target_cols]

# Split the data into training and testing sets (80/20 split)
X_train_naval, X_test_naval, y_train_naval, y_test_naval = train_test_split(
    X_naval, y_naval, test_size=0.2, random_state=42
)

print("Naval data split into training and testing sets.")
print("X_train_naval shape:", X_train_naval.shape)
print("X_test_naval shape:", X_test_naval.shape)
print("y_train_naval shape:", y_train_naval.shape)
print("y_test_naval shape:", y_test_naval.shape)

"""### 2.4. Model Training (XGBoost Regressor)
Now we will train the XGBoost regressor on the naval vessel training data. XGBoost natively supports multi-output regression, so we can train one model to predict both target variables.
"""



# Initialize the XGBoost Regressor
# We use the default 'reg:squarederror' objective for regression.
xgb_regressor = xgb.XGBRegressor(
    objective='reg:squarederror',
    random_state=42
)

# Train the model on the naval training data
print("Training the XGBoost regressor...")
xgb_regressor.fit(X_train_naval, y_train_naval)
print("Regressor model training complete.")

"""### 2.5. Regression Model Evaluation
Now that the model is trained, let's evaluate its performance on the unseen test data using common regression metrics. We'll assess the performance for each of the two target variables independently.
"""

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Make predictions on the test set
y_pred_naval = xgb_regressor.predict(X_test_naval)

# For clarity, let's put the predictions into a DataFrame with the correct column names
y_pred_df = pd.DataFrame(y_pred_naval, columns=target_cols)

print("Regression Model Evaluation Metrics:\n")

# Evaluate for the first target: Compressor decay
print(f"--- Target 1: {target_cols[0]} ---")
r2_compressor = r2_score(y_test_naval[target_cols[0]], y_pred_df[target_cols[0]])
mse_compressor = mean_squared_error(y_test_naval[target_cols[0]], y_pred_df[target_cols[0]])
mae_compressor = mean_absolute_error(y_test_naval[target_cols[0]], y_pred_df[target_cols[0]])
rmse_compressor = np.sqrt(mse_compressor)

print(f"  R-squared (R²): {r2_compressor:.4f}")
print(f"  Mean Squared Error (MSE): {mse_compressor:.6f}")
print(f"  Mean Absolute Error (MAE): {mae_compressor:.6f}")
print(f"  Root Mean Squared Error (RMSE): {rmse_compressor:.6f}\n")


# Evaluate for the second target: Turbine decay
print(f"--- Target 2: {target_cols[1]} ---")
r2_turbine = r2_score(y_test_naval[target_cols[1]], y_pred_df[target_cols[1]])
mse_turbine = mean_squared_error(y_test_naval[target_cols[1]], y_pred_df[target_cols[1]])
mae_turbine = mean_absolute_error(y_test_naval[target_cols[1]], y_pred_df[target_cols[1]])
rmse_turbine = np.sqrt(mse_turbine)

print(f"  R-squared (R²): {r2_turbine:.4f}")
print(f"  Mean Squared Error (MSE): {mse_turbine:.6f}")
print(f"  Mean Absolute Error (MAE): {mae_turbine:.6f}")
print(f"  Root Mean Squared Error (RMSE): {rmse_turbine:.6f}")

"""### 2.6. Regression Model Explainability (SHAP)
Just like with our first model, we'll use SHAP to understand the predictions of our regressor.
"""

# Initialize the SHAP explainer for our regressor model
reg_explainer = shap.TreeExplainer(xgb_regressor)

# Calculate SHAP values for the naval test set
print("Calculating SHAP values for the naval test set...")
naval_shap_values = reg_explainer(X_test_naval)
print("SHAP values calculated.")

# For multi-output regression, SHAP provides values for each output.
# We can access them via naval_shap_values.values[:, :, 0] for the first target, etc.

"""#### Global Feature Importance for Regression Targets
Let's visualize the feature importance for each of our two target variables.
"""

# Generate the SHAP summary plot for the first target (Compressor Decay)
print(f"SHAP Summary Plot for {target_cols[0]}")
shap.summary_plot(naval_shap_values.values[:, :, 0], X_test_naval, plot_type="dot")

# Generate the SHAP summary plot for the second target (Turbine Decay)
print(f"\nSHAP Summary Plot for {target_cols[1]}")
shap.summary_plot(naval_shap_values.values[:, :, 1], X_test_naval, plot_type="dot")

"""### 2.7. Regression Model Serialization
Finally, let's save our newly trained regression model and its SHAP explainer.
"""

# Define the paths to save the model and explainer
naval_model_path = 'models/naval_model.pkl'
naval_explainer_path = 'models/naval_shap_explainer.pkl'

# Save the regression model
joblib.dump(xgb_regressor, naval_model_path)
print(f"Regression model saved to {naval_model_path}")

# Save the SHAP explainer for the regressor
joblib.dump(reg_explainer, naval_explainer_path)
print(f"Regression SHAP explainer saved to {naval_explainer_path}")

from google.colab import drive
drive.mount('/content/drive')